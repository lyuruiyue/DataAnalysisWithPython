{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search:vote trump\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests_oauthlib import OAuth1\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "\n",
    "search_url = 'https://api.twitter.com/1.1/search/tweets.json?q='\n",
    "search_term = input(\"Search:\")\n",
    "\n",
    "search_url = search_url + search_term + '&count=100'\n",
    "    \n",
    "consumer_key = 'ajPMhCizj8t5TWsMCBA3Hw3sb'\n",
    "consumer_secret = '5jH2mzn59NQCV4KJP7Aiv1ZyuDN2pEvbAezAtNui3m7FQsMW36'\n",
    "access_token = '789176579863695360-2qUKcpc0l8bA0QfP2ahwY8opWaZaQFY'\n",
    "access_token_secret = 'CAyupgeqZq483QNXabcDMxKLnXuZOdOjwXxA7KgXT4sad'\n",
    "auth = OAuth1(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "\n",
    "results = requests.get(search_url, auth=auth)\n",
    "better_results = results.json()\n",
    "\n",
    "#search_term+'_'+tweet['created_at'][:-17]+'H'\n",
    "if not os.path.exists(search_term):\n",
    "    os.makedirs(search_term)\n",
    "\n",
    "#fileObject = open(search_term+'/'+time.strftime(\"%Y-%m-%d %H-%M\", time.localtime())+' Min'+'.json', 'w')\n",
    "with open(search_term+'/'+time.strftime(\"%Y-%m-%d %H-%M\", time.localtime())+' Min'+'.json', 'w') as f:\n",
    "    f.write(json.dumps(better_results))\n",
    "#for tweet in better_results['statuses']:\n",
    "    \n",
    "    #jsObj = json.dumps(tweet)\n",
    "    #fileObject.write(jsObj)\n",
    "#fileObject.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search:Trump\n",
      "location:New York\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests_oauthlib import OAuth1\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim()\n",
    "search_url = 'https://api.twitter.com/1.1/search/tweets.json?q='\n",
    "\n",
    "search_term = input(\"Search:\")\n",
    "location = input(\"location:\")\n",
    "location = geolocator.geocode(location)\n",
    "\n",
    "max_range = 10\n",
    "geocode = \"%f,%f,%dmi\" % (location.latitude, location.longitude, max_range)\n",
    "url = search_url + search_term+ \"&geocode=\"+ geocode+\"&count=100\"\n",
    "\n",
    "consumer_key = 'ajPMhCizj8t5TWsMCBA3Hw3sb'\n",
    "consumer_secret = '5jH2mzn59NQCV4KJP7Aiv1ZyuDN2pEvbAezAtNui3m7FQsMW36'\n",
    "access_token = '789176579863695360-2qUKcpc0l8bA0QfP2ahwY8opWaZaQFY'\n",
    "access_token_secret = 'CAyupgeqZq483QNXabcDMxKLnXuZOdOjwXxA7KgXT4sad'\n",
    "auth = OAuth1(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "\n",
    "results = requests.get(url, auth=auth)\n",
    "better_results = results.json()\n",
    "if not os.path.exists(search_term+'_with_location'):\n",
    "    os.makedirs(search_term+'_with_location')\n",
    "with open(search_term+'_with_location'+'/'+time.strftime(\"%Y-%m-%d %H-%M\", time.localtime())+' Min'+'.json', 'w') as f:\n",
    "    f.write(json.dumps(better_results))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Average followers of user who tweet about the search keyword\n",
    "## 2.Tweets amount in Boston and New York related to the keyword\n",
    "## 3.Day which tweets post the most\n",
    "## 4.Top 10 retweeted twitter related to the search keyword and location\n",
    "## 5.Top influential tweet related to the search keyword and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which analysis?4\n",
      "The top 10 retweeted twitters in Trump are:\n",
      "('RT @realDonaldTrump: The attack on Mosul is turning out to be a total disaster. We gave them months of notice. U.S. is looking so dumb. VOT…', 16100)\n",
      "('RT @HillaryClinton: Trump reportedly asked this about nuclear weapons: \"If we have them, why can\\'t we use them?\"\\n\\nWe can\\'t let him become p…', 11557)\n",
      "('RT @nytimes: Donald Trump’s Twitter insults: The complete list, printed in today’s paper https://t.co/zQCa5LnbBj https://t.co/fuwoypcDoF', 10896)\n",
      "('RT @HillaryClinton: When Trump trivializes the sacrifice of our military and veterans, he makes it clear: He has no idea what service to th…', 7076)\n",
      "('RT @HillaryClinton: \"My name is Mae Wiggins. I was denied an apartment in the Trump buildings based on the color of my skin.\" https://t.co/…', 6806)\n",
      "('RT @JamesOKeefeIII: Again, @dncpress and @AU4Change where trying to incite violence with #BirdDogging at #Trump events, but in a #DonaldDuc…', 3561)\n",
      "('RT @HillaryClinton: A (non-exhaustive) list of all the terrible things Donald Trump has said about women: https://t.co/QTCwWkrAf9', 2838)\n",
      "('RT @HillaryClinton: No one who wants to be Commander-in-Chief should be calling active military operations a \"disaster.” https://t.co/YjLRF…', 2606)\n",
      "(\"RT @HillaryClinton: When a black tenant applied for an apartment in one of Trump's buildings, she was told it wasn't available.\\n\\nA white te…\", 2524)\n",
      "(\"RT @MaxAbrahms: Al Jazeera's list of juiciest WikiLeaks forgets to mention the revelation that Qatar funds both ISIS &amp; Bill Clinton: https:…\", 2226)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "num =input(\"which analysis?\")\n",
    "#root_dir = input(\"which directory\")\n",
    "\n",
    "root_dir = 'Vote Trump'\n",
    "count1 = 0\n",
    "followers = []\n",
    "locations = []\n",
    "days = []\n",
    "for parent, dirnames, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        filepath = parent + os.sep + filename\n",
    "        if filepath.endswith(\".json\"):\n",
    "            myfile = open(filepath)\n",
    "            data = json.load(myfile)\n",
    "            for value in data[\"statuses\"]:\n",
    "                followers.append(value[\"user\"][\"followers_count\"])\n",
    "                locations.append(value[\"user\"][\"location\"])\n",
    "                days.append(value[\"created_at\"])\n",
    "if (num in \"1\"):\n",
    "    sum = 0\n",
    "    for i in range(len(followers)):\n",
    "        sum = sum + int(followers[i])\n",
    "        avg = sum/len(followers)\n",
    "    print(\"The average followers of '%s' is %f\" %(root_dir,avg))\n",
    "\n",
    "if (num in \"2\"):\n",
    "    count1 =0\n",
    "    for i in range(len(locations)):\n",
    "        city = locations[i].split(\",\")\n",
    "        if(city[0] not in \" \"):\n",
    "            if(city[0]in 'NYCNew YorkNew York CityBuffaloRochesterYonkersSyracuseAlbanyNew RochelleCheektowagaMount VernonSchenectadyUticaBrentwoodTonawanda CDPWhite PlainsHempsteadLevittown'):\n",
    "                count1 = count1 +1\n",
    "    print (\"NY: %d\" %count1)\n",
    "\n",
    "    count2=0\n",
    "    for i in range(len(locations)):\n",
    "        city = locations[i].split(\",\")\n",
    "        if(city[0] not in \" \"):\n",
    "            if(city[0]in 'MABostonmassachusettsWorcesterSpringfieldLowellCambridgeNew BedfordBrocktonQuincyLynnFall RiverNewtonSomervilleLawrenceFraminghamWalthamHaverhillLexington'):\n",
    "                count2 = count2 +1\n",
    "    print (\"MA: %d\" %count2)\n",
    "\n",
    "if (num in \"3\"):\n",
    "    m=0\n",
    "    t=0\n",
    "    w=0\n",
    "    r=0\n",
    "    f=0\n",
    "    sat=0\n",
    "    sun=0\n",
    "    dic={}\n",
    "    for i in range(len(days)):\n",
    "        day = days[i][:3]\n",
    "        if day in \"Mon\":\n",
    "            m=m+1\n",
    "        if day in \"Tue\":\n",
    "            t=t+1\n",
    "        if day in \"Wed\":\n",
    "            w=w+1\n",
    "        if day in \"Thu\":\n",
    "            r=r+1\n",
    "        if day in \"Fri\":\n",
    "            f=f+1\n",
    "        if day in \"Sat\":\n",
    "            sat=sat+1\n",
    "        if day in \"Sun\":\n",
    "            sun=sun+1\n",
    "    dic.update({\"Mon\":m})\n",
    "    dic.update({\"Tue\":t})\n",
    "    dic.update({\"Wed\":w})\n",
    "    dic.update({\"Thu\":r})\n",
    "    dic.update({\"Fri\":f})\n",
    "    dic.update({\"Sat\":sat})\n",
    "\n",
    "    dict = sorted(dic.items(), key = lambda d:d[1], reverse = True)\n",
    "    print (\"Most people tweet %s on %s\"%(root_dir,dict[0]))\n",
    "if (num in \"4\"):\n",
    "    root_dir = \"Trump_with_location\"\n",
    "    top_ten_dic={}\n",
    "    for parent, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = parent + os.sep + filename\n",
    "            if filepath.endswith(\".json\"):\n",
    "                myfile = open(filepath)\n",
    "                data = json.load(myfile)\n",
    "                for value in data[\"statuses\"]:\n",
    "                    top_ten_dic.update({value[\"text\"]:value[\"retweet_count\"]})\n",
    "    top_ten_dict = sorted(top_ten_dic.items(), key = lambda d:d[1], reverse = True)\n",
    "    print(\"The top 10 retweeted twitters in %s are:\" %(root_dir[:-14]))\n",
    "    for i in range(10):\n",
    "        print (top_ten_dict[i])\n",
    "if (num in \"5\"):\n",
    "    root_dir = \"Trump_with_location\"\n",
    "    top_inf_dic={}\n",
    "    for parent, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = parent + os.sep + filename\n",
    "            if filepath.endswith(\".json\"):\n",
    "                myfile = open(filepath)\n",
    "                data = json.load(myfile)\n",
    "                for value in data[\"statuses\"]:\n",
    "                    top_inf_dic.update({value[\"text\"]:value[\"retweet_count\"]*value[\"user\"][\"followers_count\"]})\n",
    "    top_inf_dict = sorted(top_inf_dic.items(), key = lambda d:d[1], reverse = True)\n",
    "    print (\"The top influential tweet is:\")\n",
    "    print (top_inf_dict[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trump'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
